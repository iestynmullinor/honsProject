{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We assess GPT-4 on our test set, to see how it performs compared to our fine-tuned Llama-2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/26/a1/75474477af2a1dae3a25f80b72bbaf20e8296191ece7fff2f67984206f33/openai-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting python-dotenv\n",
      "  Obtaining dependency information for python-dotenv from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/bf/cd/d6d9bb1dadf73e7af02d18225cbd2c93f8552e13130484f1c8dcfece292b/anyio-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/db/dc/afecbd9650f486889181c6d1a0d675b580c06253ea7e304588e4c7485bdb/pydantic-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/iestyn/miniconda3/envs/project/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/iestyn/miniconda3/envs/project/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/iestyn/miniconda3/envs/project/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /home/iestyn/miniconda3/envs/project/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/11/a6/24139fa27831cf2127fcf578d6d0a852a611f10cefecd800b1c557333d7a/httpcore-1.0.3-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.16.2 from https://files.pythonhosted.org/packages/ad/03/1cac52dfe893109a1571956755061df771457f33cb55264baed8f89635d6/pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: sniffio, python-dotenv, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0 pydantic-2.6.1 pydantic-core-2.16.2 python-dotenv-1.0.1 sniffio-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = \"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(claim, evidence):\n",
    "  return [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"Given a ”claim” sentence and an ”evidence” sentence, determine if the evidence supports or refutes the claim, or if there is not enough information.\\n\n",
    "                                    Return the answer as the corresponding label ”SUPPORTS” or ”REFUTES” or ”NOT_ENOUGH_INFO”. \\n\n",
    "                                    Only include the label in the your response.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Claim: ’{claim}’ \\n Evidence: ’{evidence}’\"}\n",
    "    \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataset_name = \"../climate_fever/labelled-test-data.csv\"\n",
    "\n",
    "test_data_df = pd.read_csv(dataset_name)\n",
    "\n",
    "true_labels = test_data_df[\"label\"] \n",
    "\n",
    "input_data = [create_input(claim, evidence) for claim, evidence in zip(test_data_df[\"claim\"], test_data_df[\"evidence\"])]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "print(len(input_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictions: 100%|██████████| 475/475 [06:58<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add progress bar\n",
    "\n",
    "# this is commented out because it costs a fiver to run\n",
    "\n",
    "# with tqdm(total=len(input_data), desc=\"Predictions\") as pbar:\n",
    "#     for i, input in enumerate(input_data):\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4-turbo-preview\",\n",
    "#             messages=input\n",
    "#         )\n",
    "#         predictions.append(response.choices[0].message.content)\n",
    "#         # write predictions to output file after each prediction in case of crash\n",
    "\n",
    "#         with open(\"predictions_gpt4.txt\", \"w\") as f:\n",
    "#             for prediction in predictions:\n",
    "#                 f.write(prediction + \"\\n\")\n",
    "        \n",
    "#         pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "NOT_ENOUGH_INFO       0.79      0.80      0.80       305\n",
      "        REFUTES       0.45      0.44      0.45        45\n",
      "       SUPPORTS       0.66      0.66      0.66       125\n",
      "\n",
      "       accuracy                           0.73       475\n",
      "      macro avg       0.64      0.64      0.64       475\n",
      "   weighted avg       0.73      0.73      0.73       475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macro_label(micro_labels):\n",
    "    if \"REFUTES\" in micro_labels and \"SUPPORTS\" in micro_labels:\n",
    "        return \"DISPUTED\"\n",
    "    elif \"REFUTES\" in micro_labels:\n",
    "        return \"REFUTES\"\n",
    "    elif \"SUPPORTS\" in micro_labels:\n",
    "        return \"SUPPORTS\"\n",
    "    else:\n",
    "        return \"NOT_ENOUGH_INFO\"\n",
    "\n",
    "def get_macro_labels_from_micro(micro_labels):\n",
    "  macro_label_predictions=[]\n",
    "  for i in range(0, len(micro_labels), 5):\n",
    "    micro_labels_for_claim = micro_labels[i:i+5]\n",
    "    macro_label_prediction = get_macro_label(micro_labels_for_claim)\n",
    "    macro_label_predictions.append(macro_label_prediction)\n",
    "  return macro_label_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       DISPUTED       0.33      0.25      0.29         8\n",
      "NOT_ENOUGH_INFO       0.57      0.62      0.59        26\n",
      "        REFUTES       0.50      0.60      0.55        15\n",
      "       SUPPORTS       0.79      0.74      0.76        46\n",
      "\n",
      "       accuracy                           0.64        95\n",
      "      macro avg       0.55      0.55      0.55        95\n",
      "   weighted avg       0.65      0.64      0.64        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_macro_labels = get_macro_labels_from_micro(true_labels.tolist())\n",
    "predicted_macro_labels = get_macro_labels_from_micro(predictions)\n",
    "\n",
    "print(classification_report(gold_macro_labels, predicted_macro_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
