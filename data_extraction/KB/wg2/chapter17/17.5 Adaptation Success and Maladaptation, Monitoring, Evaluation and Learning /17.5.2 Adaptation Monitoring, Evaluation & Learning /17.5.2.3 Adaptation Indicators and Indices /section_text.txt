A set of all-purpose and globally applicable standard indicators that could comprehensively measure adaptation does not exist (high confidence) (IPCC, 2014; Leiter and Pringle, 2018). A wide variety of indicators have been used to assess adaptation and its results (CARE, 2010; Harvey et al., 2011; Lamhauge et al., 2013; Brooks et al., 2014; Hammill et al., 2014b; Mäkinen et al., 2018; HM Government, 2019). Literature has also noted unrealistic expectations of what indicators can accomplish. For instance, decisions involving competing political interests would not be adequately informed through simple indicators; and learning requires knowledge of how and why change has happened, something that indicators often do not capture (Hinkel, 2011; Bours et al., 2014b). Indicators can also become misguided incentives and might steer attention away from what matters (Leiter and Pringle, 2018; Hallegatte and Engle, 2019; Klonschinski, 2021). Surveys, scorecards, interviews and focus groups are alternative methods of gaining insights on adaptation progress (Brooks et al., 2014; Porter et al., 2015; Das, 2019; McNamara et al., 2020).The difficulties of assessing adaptation and an emphasis on short-term results have contributed to the common practice of relying on easily quantifiable indicators rather than assessing actual changes, that is, outcomes and impacts (World Bank Independent Evaluation Group, 2012; Fisher et al., 2015). In fact, indicators used by international climate funds largely measure outputs which provide little evidence of the actual effectiveness of adaptation, that is, its outcomes and impacts (GCF Independent Evaluation Unit, 2018; Leiter et al., 2019; Pauw et al., 2020).Indices, the combination of multiple indicators into a single score, are common products of risk and vulnerability assessments to compare countries or other entities, often in the form of rankings or maps (Preston et al., 2011; Reckien, 2018; de Sherbinin and et al., 2019). They can indicate changes in vulnerability over time within their respective conceptualisation of vulnerability or risk. The construction of indices, including indicator selection, their weighting, normalisation and data sources, has a profound impact on their scores (Reckien, 2018). Research has consistently found large discrepancies between country vulnerability rankings (Brooks et al., 2005; Eriksen and Kelly, 2007; Leiter et al., 2017b; Visser et al., 2020). Reviews of vulnerability and resilience indices identified ‘substantial conceptual, methodological and empirical weaknesses’ (Füssel, 2010: 8) and a widespread lack of validation (Cai et al., 2018). Using countries as a unit of analysis also masks significant sub-national variation (Otto et al., 2015; Mohammadpour et al., 2019). Individual indices therefore ‘fail to convene a robust guidance for policy makers’ (Muccione et al., 2017: 4) and should not present the sole basis for policy decisions (Brooks et al., 2005; Leiter and Pringle, 2018). Due to their limitations (Singh et al., 2017), the OECD suggests that indices are primarily used for ‘initiating discussion and stimulating public interest’ (OECD, 2008: 13).