Responses to climate change are facilitated when leaders, policymakers, resource managers and their constituencies share a basic understanding of the causes, effects, and possible future course of climate change (SR1.5, IPCC, 2018; SRCCL, IPCC, 2019a). Achieving shared understanding is complicated, since scientific knowledge interacts with pre-existing conceptions of weather and climate that have built up in diverse world cultures over centuries, and which are often embedded in strongly held values and beliefs stemming from ethnic or national identities, traditions, religions, and lived relationships to weather, land and sea (Van Asselt and Rotmans, 1996; Rayner and Malone, 1998; Hulme, 2009, 2018; Green et al., 2010; Jasanoff, 2010; Orlove et al., 2010; Nakashima et al., 2012; Shepherd and Sobel, 2020).These diverse, more local understandings can both contrast with and enrich the planetary-scale analyses of global climate science (high confidence).Political cultures also give rise to variation in how climate science knowledge is interpreted, used and challenged (Leiserowitz, 2006; Oreskes and Conway, 2010; Brulle et al., 2012; Dunlap and Jacques, 2013; Mahony, 2014, 2015; Brulle, 2019). A meta-analysis of 87 studies carried out between 1998 and 2016 (62 USA national, 16 non-USA national, 9 cross-national) found that political orientation and political party identification were the second most important predictors of views on climate change after environmental values (McCright et al. 2016). Ruiz et al. (2020) systematically reviewed 34 studies of non-US nations or clusters of nations and 30 studies of the USA alone. They found that in the non-US studies, ‘changed weather’ and ‘socio-altruistic values’ were the most important drivers of public attitudes. For the USA case, by contrast, political affiliation and the influence of corporations were most important. Widely varying media treatment of climate issues also affects public responses (Section 1.2.3.4). In summary, environmental and socio-altruistic values are the most significant influences on public opinion about climate change globally, while political views, political party affiliation, and corporate influence also had strong effects, especially in the USA (high confidence).Furthermore, climate change itself is not uniform. Some regions face steady, readily observable change, while others experience high variability that masks underlying trends (Section 1.4.1); mostregions are subject to hazards, but some may also experience benefits, at least temporarily (Chapters 11, 12 and Atlas). This non-uniformity may lead to wide variation in public climate change awareness and risk perceptions at multiple scales (Howe et al., 2015; Lee et al., 2015). For example, short-term temperature trends, such as cold spells or warm days, have been shown to influence public concern (Hamilton and Stampone, 2013; Zaval et al., 2014; Bohr, 2017).Given these manifold influences and the highly varied contexts of climate change communication, special care is required when expressing findings and uncertainties, including IPCC assessments that inform decision making. Throughout the IPCC’s history, all three Working Groups have sought to explicitly assess and communicate scientific uncertainty (Le Treut et al., 2007; Cubasch et al., 2013). Over time, the IPCC has developed and revised a framework to treat uncertainties consistently across assessment cycles, reports, and Working Groups through the use of calibrated language (Moss and Schneider, 2000; IPCC, 2005). Since its First Assessment Report (FAR; IPCC, 1990a), the IPCC has specified terms and methods for communicating authors’ expert judgments (Mastrandrea and Mach, 2011). During the AR5 cycle, this calibrated uncertainty language was updated and unified across all Working Groups (Mastrandrea et al., 2010, 2011). Box 1.1 summarizes this framework as it is used in AR6.Box 1.1 | Treatment of Uncertainty and Calibrated Uncertainty Language in AR6The AR6 follows the approach developed for AR5 (Box 1.1, Figure 1), as described in the ‘Guidance Notes for Lead Authors of the IPCC Fifth Assessment Report on Consistent Treatment of Uncertainties’ (Mastrandrea et al., 2010). The uncertainty Guidance Note used in AR6 clarifies the relationship between the qualitative description of confidence and the quantitative representation of uncertainty expressed by the likelihood scale. The calibrated uncertainty language emphasizes traceability of the assessment throughout the process. Key chapter findings presented in each chapter’s Executive Summary are supported in the chapter text by a summary of the underlying literature that is assessed in terms of evidence and agreement, confidence, and also likelihood, if applicable.In all three Working Groups, author teams evaluate underlying scientific understanding and use two metrics to communicate the degree of certainty in key findings. These metrics are: confidence: a qualitative measure of the validity of a finding, based on the type, amount, quality and consistency of evidence (e.g., data, mechanistic understanding, theory, models, expert judgment) and the degree of agreement.Likelihood: a quantitative measure of uncertainty in a finding, expressed probabilistically (e.g., based on statistical analysis of observations or model results, or both, and expert judgement by the author team or from a formal quantitative survey of expert views, or both).Throughout IPCC reports, the calibrated language indicating a formal confidence assessment is clearly identified byitalics (e.g., medium confidence). Where appropriate, findings can also be formulated as statements of fact without uncertainty qualifiers.Box.1.1, Figure 1 (adapted from Mach et al., 2017) shows the idealized step-by-step process by which IPCC authors assess scientific understanding and uncertainties. It starts with the evaluation of the available evidence and agreement (steps 1–2). The following summary terms are used to describe the available evidence: limited, medium, orrobust; and the degree of agreement: low, medium, or high. Generally, evidence is most robust when there are multiple, consistent, independent lines of high-quality evidence.If the author team concludes that there is sufficient evidence and agreement, the level of confidence can be evaluated. In this step, assessments of evidence and agreement are combined into a single metric (steps 3–5). The assessed level of confidence is expressed using five qualifiers: very low, low, medium, high,  and very high. Step 4 depicts how summary statements for evidence and agreement relate to confidence levels. For a given evidence and agreement statement, different confidence levels can be assigned depending on the context, but increasing levels of evidence and degrees of agreement correlate with increasing confidence. When confidence in a finding is assessed to be low, this does not necessarily mean that confidence in its opposite is  high,  and vice versa. Similarly, low confidence does not imply distrust in the finding; instead, it means that the statement is the best conclusion based on currently available knowledge. Further research and methodological progress may change the level of confidence in any finding in future assessments.Ifthe expert judgement of the author team concludes that there is sufficient confidence and quantitative/probabilistic evidence, assessment conclusions can be expressed with likelihood statements (steps 5–6). Unless otherwise indicated, likelihood statements are related to findings for which the authors’ assessment of confidence is  highorvery high. Terms used to indicate the assessed likelihood of an outcome include: virtually certain: 99–100% probability, very likely : 90–100%, likely : 66–100%, about as likely as not : 33–66%, unlikely : 0–33%, very unlikely : 0–10%, exceptionally unlikely : 0–1%. Additional terms (extremely likely : 95–100%, more likely than not >50–100%, and extremely unlikely 0–5%) may also be used when appropriate.Likelihood can indicate probabilities for single events or broader outcomes. The probabilistic information may build from statistical or modelling analyses, other quantitative analyses, or expert elicitation. The framework encourages authors, where appropriate, to present probability more precisely than can be done with the likelihood scale, for example with complete probability distributions or percentile ranges, including quantification of tails of distributions, which are important for risk management (Sections 1.2.2 and 1.4.4; Mach et al., 2017). In some instances, multiple combinations of confidence and likelihood are possible to characterize key findingsBox 1.1Box 1.1, Figure 1 | The IPCC AR6 approach for characterizing understanding and uncertainty in assessment findings. This diagram illustrates the step-by-step process authors use to evaluate and communicate the state of knowledge in their assessment (Mastrandrea et al., 2010). Authors present evidence/agreement, confidence, or likelihood terms with assessment conclusions, communicating their expert judgments accordingly. Example conclusions drawn from Report are presented in the box at the bottom of the figure. Figure adapted from Mach et al. (2017) .Open figureFor example, avery likely statement might be made with  high confidence, whereas a likely statement might be made with very high confidence. In these instances, the author teams consider which statement will convey the most balanced information to the reader.Throughout this WGI Report, unless stated otherwise, uncertainty is quantified using 90% uncertainty intervals. The 90% uncertainty interval, reported in square brackets [x to y], is estimated to have a 90% likelihood of covering the value that is being estimated. The range encompasses the median value and there is an estimated 10% combined likelihood of the value being below the lower end of the range (x) and above its upper end (y). Often the distribution will be considered symmetric about the corresponding best estimate (as in the illustrative example in the figure), but this is not always the case. In this report, an assessed 90% uncertainty interval is referred to as a ‘very likely range’. Similarly, an assessed 66% uncertainty interval is referred to as a ‘likely range’.Considerable critical attention has focused on whether applying the IPCC framework effectively achieves consistent treatment of uncertainties and clear communication of findings to users (Shapiro et al., 2010; Adler and Hirsch Hadorn, 2014). Specific concerns include, for example, the transparency and traceability of expert judgements underlying the assessment conclusions (Oppenheimer et al., 2016) and the context-dependent representations and interpretations of probability terms (Budescu et al., 2009, 2012; Janzwood, 2020). Budescu et al. (2014) surveyed 25 samples in 24 countries (a total of 10,792 individual responses), finding that even when shown IPCC uncertainty guidance, lay readers systematically misunderstood IPCC likelihood statements. When presented with a ‘high likelihood’ statement, they understood it as indicating a lower likelihood than intended by the IPCC authors. Conversely, they interpreted ‘low likelihood’ statements as indicating a higher likelihood than intended. In another study, British lay readers interpreted uncertainty language somewhat differently from IPCC guidance, but Chinese lay people reading the same uncertainty language translated into Chinese differed much more in their interpretations (Harris et al., 2013). Further, even though it is objectively more probable that wide uncertainty intervals will encompass true values, wide intervals were interpreted by lay people as implying subjective uncertainty or lack of knowledge on the part of scientists (Løhre et al., 2019). Mach et al. (2017) investigated the advances and challenges in approaches to expert judgment in AR5. Their analysis showed that the shared framework increased the overall comparability of assessment conclusions across all Working Groups and topics related to climate change, from the physical science basis to resulting impacts, risks, and options for response. Nevertheless, many challenges in developing and communicating assessment conclusions persist, especially for findings drawn from multiple disciplines and Working Groups, for subjective aspects of judgements, and for findings with substantial uncertainties (Adler and Hirsch Hadorn, 2014). In summary, the calibrated language cannot entirely prevent misunderstandings, including a tendency to systematically underestimate the probability of the IPCC’s higher-likelihood conclusions and overestimate the probability of the lower-likelihood ones (high confidence). However, a consistent and systematic approach across Working Groups to communicate the assessment outcomes is an important characteristic of the IPCC.Some suggested alternatives are impractical, such as always including numerical values along with calibrated language (Budescu et al., 2014). Others, such as using positive instead of negative expressions of low-to-medium probabilities, show promise but were not proposed in time for adoption in AR6 (Juanchich et al., 2020). This report therefore retains the same calibrated language used in AR5 (Box 1.1). Like previous reports, AR6 also includes FAQs that express its chief conclusions in plain language designed for lay readers.The framework for communicating uncertainties does not allow for indicating cases where ‘deep uncertainty’ is identified in the assessment (Adler and Hirsch Hadorn, 2014). The definition of deep uncertainty in IPCC assessments has been described in the context of SROCC (IPCC, 2019b; Box 5 in Abram et al., 2019): a situation of deep uncertainty exists when experts or stakeholders do not know or cannot agree on: (i) appropriate conceptual models that describe relationships among key driving forces in a system; (ii) the probability distributions used to represent uncertainty about key variables and parameters; and/or (iii) how to weigh and value desirable alternative outcomes (Cross-Chapter Box 1.2 and Annex VII: Glossary; Abram et al., 2019). Since AR5, ‘storylines’ or ‘narratives’ approaches have been used to address issues related to deep uncertainty, for example low-likelihood events that would have high impact if they occurred, to better inform risk assessment and decision making (Section 1.4.4). Chapter 9 (Section 9.2.3) notes deep uncertainty in long-term projections for sea level rise, and in processes related to marine ice-sheet instability and marine ice cliff instability.