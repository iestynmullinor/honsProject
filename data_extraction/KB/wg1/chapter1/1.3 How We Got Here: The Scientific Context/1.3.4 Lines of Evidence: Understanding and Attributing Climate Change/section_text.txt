Understanding the global climate system requires both theoretical understanding and empirical measurement of the major forces and factors that govern the transport of energy and mass (air, water and water vapour) around the globe; the chemical and physical properties of the atmosphere, ocean, cryosphere and land surfaces; and the biological and physical dynamics of natural ecosystems, as well as the numerous feedbacks (both positive and negative) among these processes. Attributing climatic changes or extreme weather events to human activity (Cross-Working Group Box: Attribution) also requires an understanding of the many ways that human activities may affect the climate, along with statistical and other techniques for separating the ‘signal’ of anthropogenic climate change from the ‘noise’ of natural climate variability (Section 1.4.2). This inter- and trans-disciplinary effort requires contributions from many sciences.Due to the complexity of many interacting processes, ranging in scale from the molecular to the global, and occurring on time scales from seconds to millennia, attribution makes extensive use of conceptual, mathematical, and computer simulation models. Modelling allows scientists to combine a vast range of theoretical and empirical understanding from physics, chemistry and other natural sciences, producing estimates of their joint consequences as simulations of past, present or future states and trends (Nebeker, 1995; Edwards, 2010, 2011).In addition to radiative transfer (discussed above in Section 1.3.3), forces and factors such as thermodynamics (energy conversions), gravity, surface friction, and the Earth’s rotation govern the planetary-scale movements or ‘circulation’ of air and water in the climate system. The scientific theory of climate began with Halley (1686), who hypothesized vertical atmospheric circulatory cells driven by solar heating, and Hadley (1735), who showed how the Earth’s rotation affects that circulation. Ferrel (1856) added the Coriolis force to existing theory, explaining the major structures of the global atmospheric circulation. In aggregate, prevailing winds and ocean currents move energy poleward from the equatorial regions where the majority of incoming solar radiation is received.Climate models provide the ability to simulate these complex circulatory processes, and to improve the physical theory of climate by testing different mathematical formulations of those processes. Since controlled experiments at planetary scale are impossible, climate simulations provide one important way to explore the differential effects and interactions of variables such as solar irradiance, aerosols and GHGs. To assess their quality, models or components of models may be compared with observations. For this reason, they can be used to attribute observed climatic effects to different natural and human drivers (Hegerl et al., 2011). As early as Arrhenius (1896), simple mathematical models were used to calculate the effects of doubling atmospheric carbon dioxide over pre-industrial concentrations (approximately 550 ppm vs approximately 275 ppm respectively). In the early 20th century Bjerknes formulated the Navier–Stokes equations of fluid dynamics for motion of the atmosphere (Bjerknes, 1906; Bjerknes et al., 1910), and Richardson (1922) developed a system for numerical weather prediction based on these equations. When electronic computers became available in the late 1940s, the methods of Bjerknes and Richardson were successfully applied to weather forecasting (Charney et al., 1950; Nebeker, 1995; Harper, 2008).In the 1960s similar approaches to modelling the weather were used to model the climate, but with much longer runs than daily forecasting (Smagorinsky et al., 1965; Manabe and Wetherald, 1967). Simpler statistical and one- and two-dimensional modelling approaches continued in tandem with the more complex general circulation models (GCMs; Manabe and Wetherald, 1967; Budyko, 1969; Sellers, 1969). The first coupled atmosphere–ocean model (AOGCM) with realistic topography appeared in 1975 (Bryan et al., 1975; Manabe et al., 1975). Rapid increases in computer power enabled higher resolutions, longer model simulations, and the inclusion of additional physical processes in GCMs, such as aerosols, atmospheric chemistry, sea ice, and snow.In the 1990s, AOGCMs were state of the art. By the 2010s, Earth system models (ESMs, also known as coupled carbon-cycle climate models) incorporated land surface, vegetation, the carbon cycle, and other elements of the climate system. Since the 1990s, some major modelling centres have deployed ‘unified’ models for both weather prediction and climate modelling, with the goal of a seamless modelling approach that uses the same dynamics, physics and parameterisations at multiple scales of time and space (Section 10.1.2; Cullen, 1993; Brown et al., 2012; NRC, 2012; WMO, 2015). Because weather forecast models make short-term predictions that can be frequently verified, and improved models are introduced and tested iteratively on cycles as short as 18 months, this approach allows major portions of the climate model to be evaluated as a weather model and more frequently improved. However, all climate models exhibit biases of different degrees and types, and the practice of ‘tuning’ parameter values in models to make their outputs match variables such as historical warming trajectories has generated concern throughout their history (Section 1.5.3.2; Randall and Wielicki, 1997; Edwards, 2010; Hourdin et al., 2017). Overall, AR5 WGI assessed that climate models had improved since previous reports (IPCC, 2013b).Since climate models vary along many dimensions, such as grid type, resolution, and parameterizations, comparing their results requires special techniques. To address this problem, the climate modelling community developed increasingly sophisticated model intercomparison projects (MIPs; Gates et al., 1999; Covey et al., 2003). MIPs prescribe standardized experiment designs, time periods, output variables or observational reference data to facilitate direct comparison of model results. This aids in diagnosing the reasons for biases and other differences among models, and furthers process understanding (Section 1.5). Both the CMIP3 and CMIP5 model intercomparison projects included experiments testing the ability of models to reproduce 20th-century global surface temperature trends both with and without anthropogenic forcings. Although some individual model runs failed to achieve this (Hourdin et al., 2017), the mean trends of multi-model ensembles did so successfully (Meehl et al., 2007a; Taylor et al., 2012). When only natural forcings were included (creating the equivalent of a ‘control Earth’ without human influence), similar multi-model ensembles could not reproduce the observed post-1970 warming at either global or regional scales (Edwards, 2010; Jones et al., 2013). The GCMs and ESMs compared in CMIP6 (used in this Report) offer more explicit documentation and evaluation of tuning procedures (Section 1.5; Schmidt et al., 2017; Burrows et al., 2018; Mauritsen and Roeckner, 2020).The FAR (IPCC, 1990a) concluded that while both theory and models suggested that anthropogenic warming was already well underway, its signal could not yet be detected in observational data against the ‘noise’ of natural variability (see also Section 1.4.2; and Barnett and Schlesinger, 1987). Since then, increased warming and progressively more conclusive attribution studies have identified human activities as the ‘dominant cause of the observed warming since the mid-20th century’ (IPCC, 2013b). ‘Fingerprint’ studies seek to detect specific observed changes – expected from theoretical understanding and model results – that could not be explained by natural drivers alone, and to attribute statistically the proportion of such changes that is due to human influence. These include global-scale surface warming, nights warming faster than days, tropospheric warming and stratospheric cooling, a rising tropopause, increasing ocean heat content, changed global patterns of precipitation and sea level air pressure, increasing downward longwave radiation, and decreasing upward longwave radiation (Hasselmann, 1979; Karoly et al., 1994; Schneider, 1994; Santer et al., 1995, 2013; Hegerl et al., 1996, 1997; Gillett et al., 2003; Santer, 2003; Zhang et al., 2007; Stott et al., 2010; Davy et al., 2017; Mann et al., 2017). The Cross-Working Group Box on Attribution outlines attribution methods and uses from across AR6, now including event attribution (specifying the influence of climate change on individual extreme events such as floods, or on the frequency of classes of events such as tropical cyclones). Overall, the evidence for human influence has grown substantially over time and from each IPCC report to the next.A key indicator of climate understanding is whether theoretical climate system budgets or ‘inventories’, such as the balance of incoming and outgoing energy at the surface and at the top of the atmosphere, can be quantified and balanced observationally. The global energy budget, for example, includes energy retained in the atmosphere, upper ocean, deep ocean, ice, and land surface. Church et al. (2013) assessed in AR5 with  high confidence that independent estimates of effective radiative forcing (ERF), observed heat storage, and surface warming combined to give an energy budget for the Earth that is consistent with the AR5 WGI assessed likely range of equilibrium climate sensitivity (ECS) [1.5°C to 4.5°C] to within estimated uncertainties (on ECS, see (Section 1.3.5; IPCC, 2013a). Similarly, over the period 1993–2010, when observations of all sea level components were available, AR5 WGI assessed the observed global mean sea level rise to be consistent with the sum of the observed contributions from ocean thermal expansion (due to warming) combined with changes in glaciers, the Antarctic and Greenland ice sheets, and land-water storage (high confidence). Verification that the terms of these budgets balance over recent decades provides strong evidence for our understanding of anthropogenic climate change (Cross-Chapter Box 9.1).The Appendix to (Chapter 1 (Appendix 1A) lists the key detection and attribution statements in the Summaries for Policymakers of WGI reports since 1990. The evolution of these statements over time reflects the improvement of scientific understanding and the corresponding decrease in uncertainties regarding human influence. The Second Assessment Report (SAR) stated that ‘the balance of evidence suggests a discernible human influence on global climate’ (IPCC, 1995b). Five years later, the Third Assessment Report (TAR) concluded that ‘there is new and stronger evidence that most of the warming observed over the last 50 years is attributable to human activities’ (IPCC, 2001b). The AR4 further strengthened previous statements, concluding that ‘most of the observed increase in global average temperatures since the mid-20th century is very likely  due to the observed increase in anthropogenic greenhouse gas concentrations’ (IPCC, 2007b). The AR5 assessed that a human contribution had been detected in: changes in warming of the atmosphere and ocean; changes in the global water cycle; reductions in snow and ice; global mean sea level rise; and changes in some climate extremes. The AR5 concluded that ‘it is extremely likely  that human influence has been the dominant cause of the observed warming since the mid-20th century’ (IPCC, 2013b).