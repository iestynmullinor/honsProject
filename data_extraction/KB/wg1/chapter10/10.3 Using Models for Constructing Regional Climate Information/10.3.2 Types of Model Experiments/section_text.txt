Experiments driven by quasi-perfect boundary conditions or predictors (observations or reanalysis) can be useful to evaluate downscaling performance (Frei et al., 2003; Laprise et al., 2013), including the simulation of observed past trends (Lorenz and Jacob, 2010; Zubler et al., 2011; Nabat et al., 2014; Gutiérrez et al., 2018; Drugé et al., 2019; Bozkurt et al., 2020) and the added value of downscaling compared to the reanalysis fields (Section 10.3.3.2). Although the reanalysis model itself can introduce biases especially for non-assimilated variables (such as precipitation) it is assumed that in such a setting, discrepancies between the modelled and observed climate arise mostly from errors in the downscaling method (Laprise et al., 2013) or internal climate variability generated by the downscaling method (Böhnisch et al., 2020; Ehmele et al., 2020). Since AR5, reanalysis-driven RCMs have been extensively evaluated for many regions, especially in the CORDEX framework (see region specific examples in the Atlas).Over Europe, the VALUE initiative assessed statistical downscaling for marginal, temporal, and spatial aspects of temperature and precipitation including extremes, and performed a process-based evaluation of specific climatic phenomena (Gutiérrezet al., 2019; Maraun et al., 2019a). Alternatively, statistical downscaling can be evaluated in so-called perfect model or pseudo-reality simulations (Charles et al., 1999), where a high-resolution climate model simulation is used as a proxy for a hypothetical present and future realities. A statistical downscaling model is first calibrated with this pseudo present-day climate and, subsequently, assessed whether it correctly reproduces the pseudo-future conditions (Dixon et al., 2016).