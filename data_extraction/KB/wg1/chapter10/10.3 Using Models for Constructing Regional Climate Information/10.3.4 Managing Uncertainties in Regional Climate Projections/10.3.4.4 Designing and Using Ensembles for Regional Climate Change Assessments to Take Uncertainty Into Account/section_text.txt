Ensembles of climate simulations play an important role in quantifying uncertainties in the simulation output (Sections 10.3.4.2 and 10.3.4.3). In addition to providing information on internal variability, ensembles of simulations can estimate scenario uncertainty and model (structural) uncertainty. Chapter 4, especially Box 4.1, discusses issues involved with evaluating ensembles of global model simulations and their uncertainties. In a downscaling context, further considerations are necessary, such as the selection of global model–RCM combinations when performing dynamical downscaling. This is a relevant issue when resources are limited. The structural uncertainty of both the global model and the downscaling method can be important (e.g., Mearnset al., 2012; Dosio, 2017), as well as further potential uncertainty created by inconsistencies between the global model and the downscaling method (e.g., Dosio et al., 2019), which could include, for example, differences in topography or the way to model precipitation processes (Mearns et al., 2013).An important consideration is which set of global models should be used for global model–RCM combinations. If adequate resources exist, then large numbers of global model–RCM combinations are possible (Déqué et al., 2012; Coppola et al., 2021; Vautard et al., 2021). However, coordinated downscaling programmes can be limited by the human and computational resources available, for producing ensembles of downscaled output, which limits the number of feasible global model–RCM combinations. With this limitation in mind, a small set of GCMs may be chosen that span the range of equilibrium climate sensitivity in available global models (e.g., Mearns et al., 2012, 2013; Inatsu et al., 2015), though this range may be inconsistent with the likely range (Chapter 4), or some other relevant measure of sensitivity, such as the projected range of tropical SSTs (Suzuki-Parker et al., 2018). A further choice is to emphasize models that do not have the same origins or that do not use similar parametrizations and thus might be viewed as independent, a criterion that could be applied to both global models (Chapter 4) and RCMs (Evans et al., 2014). Global models and RCMs could also be discarded that unrealistically represent processes controlling the regional climate of interest (McSweeney et al., 2015; Maraun et al., 2017; Bukovsky et al., 2019; Eyring et al., 2019). Box 4.1 offers a more detailed discussion of the issues surrounding these approaches. Finally, global models may be selected to represent different physically self-consistent changes in regional climate (Zappa and Shepherd, 2017). Statistical methods can provide estimates of outcomes from missing global model–RCM combinations in a large matrix (Déqué et al., 2012; Heinrich et al., 2014; Evin et al., 2019).However, even using a relatively small set of global models can still involve substantial computation that strains available resources, both for performing the simulations and for using all simulations in the ensemble for further impacts assessment. The NARCCAP programme (Mearns et al., 2012) used only a subset of its possible global model–RCM combinations that balanced comprehensiveness of sampling the matrix with economy of computation demand, while still allowing discrimination, via ANOVA methods, of global model and RCM influences on regional climate change (Mearns et al., 2013). An advantage of the sparse, but balanced matrix for those using the downscaling output for further studies, is that they have a smaller, yet comprehensive set of global model–RCM combinations to work with. Alternatively, data-clustering methods can clump together downscaling simulations featuring similar climate-change characteristics, so that only one representative simulation from each cluster may be needed for further impacts analysis, again systematically reducing the necessary number of simulations to work with (Mendlik andGobiet, 2016; Wilcke and Bärring, 2016).Independently of the resources, participation of multiple models in a simulation programme such as CORDEX for RCMs or CMIP for global models creates ensembles of opportunity, which are ensembles populated by models that participants chose to use without there necessarily being an overarching guiding principle for an optimum choice. As discussed in Chapter 4, these ensembles are likely suboptimal for assessing sources of uncertainty. An important contributor to the suboptimal character of such an ensemble is that the models are not independent. Some may also have larger biases than others. Yet often, the output from models in these ensembles has received equal weight when viewed collectively, as was the case in much of the AR5 assessment (e.g., Collins et al., 2013b; Knutti et al., 2013; Flato et al., 2014; Kirtman et al., 2014). A number of emerging methodologies aim at optimizing the ensembles available by weighting the simulation results according to a number of criteria relevant at the regional scale that aim at obtaining more realistic estimates of the uncertainty (Sanderson et al., 2015; Brunner et al., 2020).There is  high confidence that ensembles for regional climate projections should be selected such that models unrealistically simulating processes relevant for a given application are discarded, but at the same time, the chosen ensemble spans an appropriate range of projection uncertainties.