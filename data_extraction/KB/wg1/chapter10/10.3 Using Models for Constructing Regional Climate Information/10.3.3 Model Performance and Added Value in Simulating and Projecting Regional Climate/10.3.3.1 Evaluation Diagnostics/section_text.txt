Since AR5, model evaluation has made use of a broad combination of diagnostics (Colette et al., 2012; Kotlarski et al., 2014; Eyring et al., 2016b; Gleckler et al., 2016; Ivanov et al., 2017, 2018; Vautard et al., 2021), ranging from long-term means to indices of extreme events (Zhang et al., 2011; Sillmann et al., 2013) or a combination of these (Dittus et al., 2016). This evaluation has shown that global models have pervasive biases in some aspects of their large-scale behaviour (Section 1.5.3.1, Chapter 3). More complex diagnostics are used to characterize specific meteorological phenomena (Sprenger et al., 2017), such as feedbacks in the El Niño–Southern Oscillation (ENSO; Bellenger et al., 2014), Madden-Julian Oscillation (MJO) characteristics (Benedict et al., 2014; Jiang et al., 2015; D. Kim et al., 2015; Ahn et al., 2017), extratropical modes of variability (Lee et al., 2019), cyclone tracking (Neu et al., 2013; Flaounas et al., 2018), front detection (Hope et al., 2014; Schemm et al., 2015), thunderstorm environment parameters (Bukovsky et al., 2017), African easterly waves (McCrary et al., 2014; Martin and Thorncroft, 2015), land–atmosphere coupling (Spennemann and Saulo, 2015; Santanello et al., 2018), and sea–atmosphere coupling (Bellenger et al., 2014; Mayer et al., 2017).New diagnostics for multivariate dependencies are needed to characterize compound events (Section 11.8; Hobaek Haff et al., 2015; Wahl et al., 2015; Sippel et al., 2016, 2017; Tencer et al., 2016; Bevacqua et al., 2017; Careto et al., 2018; Zscheischler et al., 2018). However, their success depends on the availability of adequate observational data (Section 10.2.2). Multivariate dependencies discovered in compound events can also be used for designing and evaluating multivariate bias adjustment and statistical downscaling. Process-based diagnostics are useful for identifying the cause of model errors, although it is not always possible to associate a systematic error with a specific cause (Eyring et al., 2019). AR5 discussed two approaches of process-based evaluation: (i) the isolation of physical components or parametrizations by dedicated experiments (Section 10.3.2.4) and (ii) diagnostics conditioned on relevant regimes, usually synoptic-scale weather patterns. The regime-based approach has been used with both global models (e.g., Barton et al., 2012; Catto et al., 2015; Taylor et al., 2019) and RCMs (Endris et al., 2016; Bukovsky et al., 2017; Whan and Zwiers, 2017; Pinto et al., 2018), but also with perfect prognosis and bias adjustment methods (Marteau et al., 2015; Addor et al., 2016; Beranová and Kyselý, 2016; Soares and Cardoso, 2018; Soares et al., 2019b).Recent studies highlight the importance of user-defined or user-relevant diagnostics for model evaluation (Maraun et al., 2015; Rhoades et al., 2018; Rössler et al., 2019b; Nissan et al., 2020). Diagnostics have been used to assess the performance of climate models to produce useful input data for impact models as in the comparison between RCMs and convection-permitting models to capture flood-generating precipitation events in the Alps (Reszler et al., 2018). Alternatively, the observed impact can be compared to that simulated by an impact model that uses input from both observations and climate models. This approach has been used to evaluate the influence of statistical downscaling and bias adjustment on hydrological (Rojas et al., 2011; H. Chen et al., 2012; Gutiérrez et al., 2019; Rössler et al., 2019b), agricultural (Ruiz-Ramos et al., 2016; Galmarini et al., 2019), forest and wildfire (Abatzoglou and Brown, 2012; Migliavacca et al., 2013) (Bedia et al., 2013), snow depth (Verfaillie et al., 2017), and regional ocean modelling (e.g., Macias et al., 2018).There is  high confidence that to assess whether a climate model realistically simulates required aspects of present-day regional climate, and to increase confidence of future projections of these aspects, evaluation needs to be based on diagnostics taking into account multiple variables and process understanding.